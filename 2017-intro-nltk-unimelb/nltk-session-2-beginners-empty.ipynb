{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img style=\"float:left\" src=\"http://ipython.org/_static/IPy_header.png\" />\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2: Loading text, tokenisation, tagging, dictionaries and ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Welcome back!**\n",
    "\n",
    "So, what did we learn yesterday? A brief recap:\n",
    "\n",
    "* The **IPython** Notebook\n",
    "* **Python**: syntax, variables, functions, etc.\n",
    "\n",
    "Today's focus will be on **developing more advanced NLTK skills** and using these skills to **investigate our own data**. \n",
    "\n",
    "*Any questions or anything before we dive in?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirty data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're going beyond nltk example data, we're bond to run into dirty data.\n",
    "\n",
    "A common part of corpus building is corpus cleaning. Reasons for cleaning include:\n",
    "\n",
    "1. Not break the code with unexpected input\n",
    "2. Ensure that searches match as many examples as possible\n",
    "3. Increasing readability, the accuracy of taggers, stemmers, parsers, etc.\n",
    "\n",
    "The level of kind of cleaning depends on your data, the aims of your project and where you are in your research. In the case of very clean data (lucky you!), there may be little that needs to be done. With messy data, you may need to go as far as to correct variant spellings (online conversation, very old books).\n",
    "\n",
    "If you need help with data cleaning, we offer trainings in [OpenRefine](https://github.com/yuandra/2016-02-01-data-acquisition-cleaning/blob/gh-pages/open-refine-01-intro.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What are the characteristics of clean and messy data? Any personal experiences? Discuss with your neighbours.* \n",
    "\n",
    "It will be important to bear these characteristics in mind once you start building your own datasets and corpora. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's load in our text.\n",
    "\n",
    "Google the Gutenberg Project and download a book as a plain text file. \n",
    "\n",
    "I chose [A Modest Proposal](https://www.gutenberg.org/ebooks/1080)\n",
    "\n",
    "We can also look at file contents within the IPython Notebook itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk import word_tokenize\n",
    "from nltk.text import Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge!**\n",
    "\n",
    "1. Find a .txt file from the Gutenberg Project or elsewhere and upload it to the Jupyter Notebook. \n",
    "2. Use the word_tokenize to break up the text data. \n",
    "3. Print the first 100 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = \"a_modest_proposal.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A MODEST PROPOSAL\n",
      "\n",
      "For preventing the children of poor people in Ireland, from being a\n",
      "burden on their parents or country, and for making them beneficial to\n",
      "the publick.\n",
      "\n",
      "by Dr. Jonathan Swift\n",
      "\n",
      "\n",
      "1729\n",
      "\n",
      "\n",
      "\n",
      "It is a melancholy object to those, who walk through this great town,\n",
      "or travel in the country, when they see the streets, the roads and\n",
      "cabbin-doors crowded with beggars of the female sex, followed by three,\n",
      "four, or six children, all in rags, and importuning every passenger for\n",
      "an alms. These mothers instead of being able to work for their honest\n",
      "livelihood, are forced to employ all their time in stroling to beg\n",
      "sustenance for their helpless infants who, as they grow up, either turn\n",
      "thieves for want of work, or leave their dear native country, to fight\n",
      "for the Pretender in Spain, or sell themselves to the Barbadoes.\n",
      "\n",
      "I think it is agreed by all parties, that this prodigious number of\n",
      "children in the arms, or on the backs, or at the heels of their mothers,\n",
      "and frequently of their fathers, is in the present deplorable state of\n",
      "the kingdom, a very great additional grievance; and therefore whoever\n",
      "could find out a fair, cheap and easy method of making these children\n",
      "sound and useful members of the common-wealth, would deserve so well of\n",
      "the publick, as to have his statue set up for a preserver of the nation.\n",
      "\n",
      "But my intention is very far from being confined to provide only for the\n",
      "children of professed beggars: it is of a much greater extent, and shall\n",
      "take in the whole number of infants at a certain age, who are born of\n",
      "parents in effect as little able to support them, as those who demand\n",
      "our charity in the streets.\n",
      "\n",
      "As to my own part, having turned my thoughts for many years, upon this\n",
      "important subject, and maturely weighed the several schemes of\n",
      "our projectors, I have always found them grossly mistaken in their\n",
      "computation. It is true, a child just dropt from its dam, may be\n",
      "supported by her milk, for a solar year, with little other nourishment:\n",
      "at most not above the value of two shillings, which the mother may\n",
      "certainly get, or the value in scraps, by her lawful occupation of\n",
      "begging; and it is exactly at one year old that I propose to provide for\n",
      "them in such a manner, as, instead of being a charge upon their parents,\n",
      "or the parish, or wanting food and raiment for the rest of their lives,\n",
      "they shall, on the contrary, contribute to the feeding, and partly to\n",
      "the cloathing of many thousands.\n",
      "\n",
      "There is likewise another great advantage in my scheme, that it will\n",
      "prevent those voluntary abortions, and that horrid practice of\n",
      "women murdering their bastard children, alas! too frequent among us,\n",
      "sacrificing the poor innocent babes, I doubt, more to avoid the expence\n",
      "than the shame, which would move tears and pity in the most savage and\n",
      "inhuman breast.\n",
      "\n",
      "The number of souls in this kingdom being usually reckoned one million\n",
      "and a half, of these I calculate there may be about two hundred thousand\n",
      "couple whose wives are breeders; from which number I subtract thirty\n",
      "thousand couple, who are able to maintain their own children, (although\n",
      "I apprehend there cannot be so many, under the present distresses of\n",
      "the kingdom) but this being granted, there will remain an hundred and\n",
      "seventy thousand breeders. I again subtract fifty thousand, for those\n",
      "women who miscarry, or whose children die by accident or disease within\n",
      "the year. There only remain an hundred and twenty thousand children of\n",
      "poor parents annually born. The question therefore is, How this number\n",
      "shall be reared, and provided for? which, as I have already said, under\n",
      "the present situation of affairs, is utterly impossible by all the\n",
      "methods hitherto proposed. For we can neither employ them in handicraft\n",
      "or agriculture; they neither build houses, (I mean in the country) nor\n",
      "cultivate land: they can very seldom pick up a livelihood by stealing\n",
      "till they arrive at six years old; except where they are of towardly\n",
      "parts, although I confess they learn the rudiments much earlier;\n",
      "during which time they can however be properly looked upon only as\n",
      "probationers: As I have been informed by a principal gentleman in the\n",
      "county of Cavan, who protested to me, that he never knew above one or\n",
      "two instances under the age of six, even in a part of the kingdom so\n",
      "renowned for the quickest proficiency in that art.\n",
      "\n",
      "I am assured by our merchants, that a boy or a girl before twelve years\n",
      "old, is no saleable commodity, and even when they come to this age, they\n",
      "will not yield above three pounds, or three pounds and half a crown\n",
      "at most, on the exchange; which cannot turn to account either to the\n",
      "parents or kingdom, the charge of nutriments and rags having been at\n",
      "least four times that value.\n",
      "\n",
      "I shall now therefore humbly propose my own thoughts, which I hope will\n",
      "not be liable to the least objection.\n",
      "\n",
      "I have been assured by a very knowing American of my acquaintance in\n",
      "London, that a young healthy child well nursed, is, at a year old, a\n",
      "most delicious nourishing and wholesome food, whether stewed, roasted,\n",
      "baked, or boiled; and I make no doubt that it will equally serve in a\n",
      "fricasie, or a ragoust.\n",
      "\n",
      "I do therefore humbly offer it to publick consideration, that of the\n",
      "hundred and twenty thousand children, already computed, twenty thousand\n",
      "may be reserved for breed, whereof only one fourth part to be males;\n",
      "which is more than we allow to sheep, black cattle, or swine, and my\n",
      "reason is, that these children are seldom the fruits of marriage, a\n",
      "circumstance not much regarded by our savages, therefore, one male will\n",
      "be sufficient to serve four females. That the remaining hundred thousand\n",
      "may, at a year old, be offered in sale to the persons of quality and\n",
      "fortune, through the kingdom, always advising the mother to let them\n",
      "suck plentifully in the last month, so as to render them plump, and fat\n",
      "for a good table. A child will make two dishes at an entertainment for\n",
      "friends, and when the family dines alone, the fore or hind quarter will\n",
      "make a reasonable dish, and seasoned with a little pepper or salt, will\n",
      "be very good boiled on the fourth day, especially in winter.\n",
      "\n",
      "I have reckoned upon a medium, that a child just born will weigh 12\n",
      "pounds, and in a solar year, if tolerably nursed, encreaseth to 28\n",
      "pounds.\n",
      "\n",
      "I grant this food will be somewhat dear, and therefore very proper for\n",
      "landlords, who, as they have already devoured most of the parents, seem\n",
      "to have the best title to the children.\n",
      "\n",
      "Infant's flesh will be in season throughout the year, but more plentiful\n",
      "in March, and a little before and after; for we are told by a grave\n",
      "author, an eminent French physician, that fish being a prolifick dyet,\n",
      "there are more children born in Roman Catholick countries about nine\n",
      "months after Lent, the markets will be more glutted than usual, because\n",
      "the number of Popish infants, is at least three to one in this kingdom,\n",
      "and therefore it will have one other collateral advantage, by lessening\n",
      "the number of Papists among us.\n",
      "\n",
      "I have already computed the charge of nursing a beggar's child (in which\n",
      "list I reckon all cottagers, labourers, and four-fifths of the farmers)\n",
      "to be about two shillings per annum, rags included; and I believe no\n",
      "gentleman would repine to give ten shillings for the carcass of a good\n",
      "fat child, which, as I have said, will make four dishes of excellent\n",
      "nutritive meat, when he hath only some particular friend, or his\n",
      "own family to dine with him. Thus the squire will learn to be a good\n",
      "landlord, and grow popular among his tenants, the mother will have eight\n",
      "shillings neat profit, and be fit for work till she produces another\n",
      "child.\n",
      "\n",
      "Those who are more thrifty (as I must confess the times require) may\n",
      "flea the carcass; the skin of which, artificially dressed, will make\n",
      "admirable gloves for ladies, and summer boots for fine gentlemen.\n",
      "\n",
      "As to our City of Dublin, shambles may be appointed for this purpose, in\n",
      "the most convenient parts of it, and butchers we may be assured will not\n",
      "be wanting; although I rather recommend buying the children alive, and\n",
      "dressing them hot from the knife, as we do roasting pigs.\n",
      "\n",
      "A very worthy person, a true lover of his country, and whose virtues\n",
      "I highly esteem, was lately pleased, in discoursing on this matter, to\n",
      "offer a refinement upon my scheme. He said, that many gentlemen of this\n",
      "kingdom, having of late destroyed their deer, he conceived that the\n",
      "want of venison might be well supply'd by the bodies of young lads and\n",
      "maidens, not exceeding fourteen years of age, nor under twelve; so great\n",
      "a number of both sexes in every country being now ready to starve for\n",
      "want of work and service: And these to be disposed of by their parents\n",
      "if alive, or otherwise by their nearest relations. But with due\n",
      "deference to so excellent a friend, and so deserving a patriot, I\n",
      "cannot be altogether in his sentiments; for as to the males, my American\n",
      "acquaintance assured me from frequent experience, that their flesh was\n",
      "generally tough and lean, like that of our school-boys, by continual\n",
      "exercise, and their taste disagreeable, and to fatten them would not\n",
      "answer the charge. Then as to the females, it would, I think, with\n",
      "humble submission, be a loss to the publick, because they soon would\n",
      "become breeders themselves: And besides, it is not improbable that some\n",
      "scrupulous people might be apt to censure such a practice, (although\n",
      "indeed very unjustly) as a little bordering upon cruelty, which, I\n",
      "confess, hath always been with me the strongest objection against any\n",
      "project, how well soever intended.\n",
      "\n",
      "But in order to justify my friend, he confessed, that this expedient\n",
      "was put into his head by the famous Salmanaazor, a native of the island\n",
      "Formosa, who came from thence to London, above twenty years ago, and in\n",
      "conversation told my friend, that in his country, when any young person\n",
      "happened to be put to death, the executioner sold the carcass to persons\n",
      "of quality, as a prime dainty; and that, in his time, the body of a\n",
      "plump girl of fifteen, who was crucified for an attempt to poison the\n",
      "Emperor, was sold to his imperial majesty's prime minister of state, and\n",
      "other great mandarins of the court in joints from the gibbet, at four\n",
      "hundred crowns. Neither indeed can I deny, that if the same use were\n",
      "made of several plump young girls in this town, who without one single\n",
      "groat to their fortunes, cannot stir abroad without a chair, and appear\n",
      "at a play-house and assemblies in foreign fineries which they never will\n",
      "pay for; the kingdom would not be the worse.\n",
      "\n",
      "Some persons of a desponding spirit are in great concern about that vast\n",
      "number of poor people, who are aged, diseased, or maimed; and I have\n",
      "been desired to employ my thoughts what course may be taken, to ease\n",
      "the nation of so grievous an incumbrance. But I am not in the least pain\n",
      "upon that matter, because it is very well known, that they are every day\n",
      "dying, and rotting, by cold and famine, and filth, and vermin, as fast\n",
      "as can be reasonably expected. And as to the young labourers, they\n",
      "are now in almost as hopeful a condition. They cannot get work, and\n",
      "consequently pine away from want of nourishment, to a degree, that if\n",
      "at any time they are accidentally hired to common labour, they have not\n",
      "strength to perform it, and thus the country and themselves are happily\n",
      "delivered from the evils to come.\n",
      "\n",
      "I have too long digressed, and therefore shall return to my subject. I\n",
      "think the advantages by the proposal which I have made are obvious and\n",
      "many, as well as of the highest importance.\n",
      "\n",
      "For first, as I have already observed, it would greatly lessen the\n",
      "number of Papists, with whom we are yearly over-run, being the principal\n",
      "breeders of the nation, as well as our most dangerous enemies, and who\n",
      "stay at home on purpose with a design to deliver the kingdom to the\n",
      "Pretender, hoping to take their advantage by the absence of so many good\n",
      "Protestants, who have chosen rather to leave their country, than stay at\n",
      "home and pay tithes against their conscience to an episcopal curate.\n",
      "\n",
      "Secondly, The poorer tenants will have something valuable of their own,\n",
      "which by law may be made liable to a distress, and help to pay their\n",
      "landlord's rent, their corn and cattle being already seized, and money a\n",
      "thing unknown.\n",
      "\n",
      "Thirdly, Whereas the maintainance of an hundred thousand children,\n",
      "from two years old, and upwards, cannot be computed at less than\n",
      "ten shillings a piece per annum, the nation's stock will be thereby\n",
      "encreased fifty thousand pounds per annum, besides the profit of a\n",
      "new dish, introduced to the tables of all gentlemen of fortune in the\n",
      "kingdom, who have any refinement in taste. And the money will circulate\n",
      "among our selves, the goods being entirely of our own growth and\n",
      "manufacture.\n",
      "\n",
      "Fourthly, The constant breeders, besides the gain of eight shillings\n",
      "sterling per annum by the sale of their children, will be rid of the\n",
      "charge of maintaining them after the first year.\n",
      "\n",
      "Fifthly, This food would likewise bring great custom to taverns,\n",
      "where the vintners will certainly be so prudent as to procure the best\n",
      "receipts for dressing it to perfection; and consequently have their\n",
      "houses frequented by all the fine gentlemen, who justly value themselves\n",
      "upon their knowledge in good eating; and a skilful cook, who understands\n",
      "how to oblige his guests, will contrive to make it as expensive as they\n",
      "please.\n",
      "\n",
      "Sixthly, This would be a great inducement to marriage, which all wise\n",
      "nations have either encouraged by rewards, or enforced by laws and\n",
      "penalties. It would encrease the care and tenderness of mothers towards\n",
      "their children, when they were sure of a settlement for life to the\n",
      "poor babes, provided in some sort by the publick, to their annual profit\n",
      "instead of expence. We should soon see an honest emulation among the\n",
      "married women, which of them could bring the fattest child to the\n",
      "market. Men would become as fond of their wives, during the time of\n",
      "their pregnancy, as they are now of their mares in foal, their cows in\n",
      "calf, or sow when they are ready to farrow; nor offer to beat or kick\n",
      "them (as is too frequent a practice) for fear of a miscarriage.\n",
      "\n",
      "Many other advantages might be enumerated. For instance, the addition\n",
      "of some thousand carcasses in our exportation of barrel'd beef: the\n",
      "propagation of swine's flesh, and improvement in the art of making good\n",
      "bacon, so much wanted among us by the great destruction of pigs,\n",
      "too frequent at our tables; which are no way comparable in taste or\n",
      "magnificence to a well grown, fat yearly child, which roasted whole will\n",
      "make a considerable figure at a Lord Mayor's feast, or any other publick\n",
      "entertainment. But this, and many others, I omit, being studious of\n",
      "brevity.\n",
      "\n",
      "Supposing that one thousand families in this city, would be constant\n",
      "customers for infants flesh, besides others who might have it at merry\n",
      "meetings, particularly at weddings and christenings, I compute that\n",
      "Dublin would take off annually about twenty thousand carcasses; and the\n",
      "rest of the kingdom (where probably they will be sold somewhat cheaper)\n",
      "the remaining eighty thousand.\n",
      "\n",
      "I can think of no one objection, that will possibly be raised against\n",
      "this proposal, unless it should be urged, that the number of people will\n",
      "be thereby much lessened in the kingdom. This I freely own, and 'twas\n",
      "indeed one principal design in offering it to the world. I desire the\n",
      "reader will observe, that I calculate my remedy for this one individual\n",
      "Kingdom of Ireland, and for no other that ever was, is, or, I think,\n",
      "ever can be upon Earth. Therefore let no man talk to me of other\n",
      "expedients: Of taxing our absentees at five shillings a pound: Of using\n",
      "neither cloaths, nor houshold furniture, except what is of our\n",
      "own growth and manufacture: Of utterly rejecting the materials and\n",
      "instruments that promote foreign luxury: Of curing the expensiveness of\n",
      "pride, vanity, idleness, and gaming in our women: Of introducing a vein\n",
      "of parsimony, prudence and temperance: Of learning to love our\n",
      "country, wherein we differ even from Laplanders, and the inhabitants\n",
      "of Topinamboo: Of quitting our animosities and factions, nor acting any\n",
      "longer like the Jews, who were murdering one another at the very moment\n",
      "their city was taken: Of being a little cautious not to sell our country\n",
      "and consciences for nothing: Of teaching landlords to have at least one\n",
      "degree of mercy towards their tenants. Lastly, of putting a spirit of\n",
      "honesty, industry, and skill into our shop-keepers, who, if a resolution\n",
      "could now be taken to buy only our native goods, would immediately unite\n",
      "to cheat and exact upon us in the price, the measure, and the goodness,\n",
      "nor could ever yet be brought to make one fair proposal of just dealing,\n",
      "though often and earnestly invited to it.\n",
      "\n",
      "Therefore I repeat, let no man talk to me of these and the like\n",
      "expedients, 'till he hath at least some glympse of hope, that there will\n",
      "ever be some hearty and sincere attempt to put them into practice.\n",
      "\n",
      "But, as to my self, having been wearied out for many years with offering\n",
      "vain, idle, visionary thoughts, and at length utterly despairing of\n",
      "success, I fortunately fell upon this proposal, which, as it is wholly\n",
      "new, so it hath something solid and real, of no expence and little\n",
      "trouble, full in our own power, and whereby we can incur no danger\n",
      "in disobliging England. For this kind of commodity will not bear\n",
      "exportation, and flesh being of too tender a consistence, to admit a\n",
      "long continuance in salt, although perhaps I could name a country, which\n",
      "would be glad to eat up our whole nation without it.\n",
      "\n",
      "After all, I am not so violently bent upon my own opinion, as to reject\n",
      "any offer, proposed by wise men, which shall be found equally innocent,\n",
      "cheap, easy, and effectual. But before something of that kind shall be\n",
      "advanced in contradiction to my scheme, and offering a better, I desire\n",
      "the author or authors will be pleased maturely to consider two points.\n",
      "First, As things now stand, how they will be able to find food and\n",
      "raiment for a hundred thousand useless mouths and backs. And secondly,\n",
      "There being a round million of creatures in humane figure throughout\n",
      "this kingdom, whose whole subsistence put into a common stock, would\n",
      "leave them in debt two million of pounds sterling, adding those who are\n",
      "beggars by profession, to the bulk of farmers, cottagers and labourers,\n",
      "with their wives and children, who are beggars in effect; I desire\n",
      "those politicians who dislike my overture, and may perhaps be so bold\n",
      "to attempt an answer, that they will first ask the parents of these\n",
      "mortals, whether they would not at this day think it a great happiness\n",
      "to have been sold for food at a year old, in the manner I prescribe, and\n",
      "thereby have avoided such a perpetual scene of misfortunes, as they have\n",
      "since gone through, by the oppression of landlords, the impossibility of\n",
      "paying rent without money or trade, the want of common sustenance, with\n",
      "neither house nor cloaths to cover them from the inclemencies of the\n",
      "weather, and the most inevitable prospect of intailing the like, or\n",
      "greater miseries, upon their breed for ever.\n",
      "\n",
      "I profess, in the sincerity of my heart, that I have not the least\n",
      "personal interest in endeavouring to promote this necessary work, having\n",
      "no other motive than the publick good of my country, by advancing\n",
      "our trade, providing for infants, relieving the poor, and giving some\n",
      "pleasure to the rich. I have no children, by which I can propose to\n",
      "get a single penny; the youngest being nine years old, and my wife past\n",
      "child-bearing.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(text_path), \"r\", encoding=\"UTF-8\")\n",
    "text = file.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'MODEST', 'PROPOSAL', 'For', 'preventing', 'the', 'children', 'of', 'poor', 'people', 'in', 'Ireland', ',', 'from', 'being', 'a', 'burden', 'on', 'their', 'parents', 'or', 'country', ',', 'and', 'for', 'making', 'them', 'beneficial', 'to', 'the', 'publick', '.', 'by', 'Dr.', 'Jonathan', 'Swift', '1729', 'It', 'is', 'a', 'melancholy', 'object', 'to', 'those', ',', 'who', 'walk', 'through', 'this', 'great', 'town', ',', 'or', 'travel', 'in', 'the', 'country', ',', 'when', 'they', 'see', 'the', 'streets', ',', 'the', 'roads', 'and', 'cabbin-doors', 'crowded', 'with', 'beggars', 'of', 'the', 'female', 'sex', ',', 'followed', 'by', 'three', ',', 'four', ',', 'or', 'six', 'children', ',', 'all', 'in', 'rags', ',', 'and', 'importuning', 'every', 'passenger', 'for', 'an', 'alms', '.', 'These', 'mothers']\n"
     ]
    }
   ],
   "source": [
    "token_text = word_tokenize(text)\n",
    "print(token_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The books were were working with yesterday had already had some processing done on them so that we could use NLTK to find features of the language. Remember that Python regards a text file as a single long string of characters. The first thing to do is to start breaking the text up into sentences and words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking a speech into tokens lets us do the sort of word counting that we were doing yesterday on the speeches. We can do some more interesting linguistic analysis if we use Part of Speech tagging. NLTK has a number of different Part of Speech tags that we could use, but the simplest one is called 'Universal', and we'll use that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', 'refuse', 'to', 'permit', 'us', 'the', 'refuse', 'permit']\n",
      "[('They', 'PRON'), ('refuse', 'VERB'), ('to', 'PRT'), ('permit', 'VERB'), ('us', 'PRON'), ('the', 'DET'), ('refuse', 'NOUN'), ('permit', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"They refuse to permit us the refuse permit\"\n",
    "token_sen = word_tokenize(sentence)\n",
    "print(token_sen)\n",
    "tagged_sen = nltk.pos_tag(token_sen, tagset=\"universal\")\n",
    "print(tagged_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of Speech tagging creates bigrams, that is, it associates the word with its tag in a pair of items that we can see above in brackets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag_fdist_sen = nltk.FreqDist(tag for (word,tag) in tagged_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PRON', 2), ('VERB', 2), ('NOUN', 2), ('PRT', 1), ('DET', 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_fdist_sen.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge!**\n",
    "\n",
    "Use Part of Speech tagging to tag the text that we have just tokenised the do the following:\n",
    "* Find the most common parts of speech\n",
    "* Find the most common verbs and create a frequency Distribution graph of your result\n",
    "* Find the 10 most common nouns in the text\n",
    "\n",
    "*Hint: to find the most common verbs and nouns, you will need to create a list that contains only the verbs or only the nouns from the speech. Use a for loop to create your list. Then create a frequency distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DET'), ('MODEST', 'NOUN'), ('PROPOSAL', 'NOUN'), ('For', 'ADP'), ('preventing', 'VERB'), ('the', 'DET'), ('children', 'NOUN'), ('of', 'ADP'), ('poor', 'ADJ'), ('people', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "tagged_text = nltk.pos_tag(token_text, tagset=\"universal\")\n",
    "print(tagged_text[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 766),\n",
       " ('VERB', 611),\n",
       " ('ADP', 510),\n",
       " ('.', 486),\n",
       " ('DET', 395),\n",
       " ('ADJ', 296),\n",
       " ('PRON', 279),\n",
       " ('ADV', 222),\n",
       " ('CONJ', 168),\n",
       " ('PRT', 121)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_fdist_text = nltk.FreqDist(tag for (word,tag) in tagged_text)\n",
    "tag_fdist_text.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n",
      "[('be', 51), ('will', 36), ('have', 29), ('are', 22), ('is', 21), ('would', 18), ('being', 16), ('can', 15), ('may', 11), ('make', 8)]\n"
     ]
    }
   ],
   "source": [
    "verblist_text = []\n",
    "for (word,tag) in tagged_text:\n",
    "    if tag == 'VERB':\n",
    "        verblist_text.append(word)\n",
    "print(len(verblist_text))\n",
    "verb_fdist = nltk.FreqDist(verblist_text)\n",
    "print(verb_fdist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766\n",
      "[('children', 19), ('kingdom', 14), ('country', 13), ('number', 11), ('thousand', 10), ('child', 9), ('year', 9), ('parents', 8), ('years', 8), ('shillings', 7), ('food', 6), ('pounds', 6), ('time', 5), ('infants', 5), ('want', 5), ('work', 5), ('nation', 5), ('charge', 5), ('breeders', 5), ('people', 4)]\n"
     ]
    }
   ],
   "source": [
    "nounlist_text = []\n",
    "for (word,tag) in tagged_text:\n",
    "    if tag == 'NOUN':\n",
    "        nounlist_text.append(word)\n",
    "print(len(nounlist_text))\n",
    "noun_fdist = nltk.FreqDist(nounlist_text)\n",
    "print(noun_fdist.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extension - COLLOCATIONS**\n",
    "There are a few things to note about this result - Project and Gutenberg have been returned as two different, very frequent nouns. Because we're humans, not computers, we know it's likely that they are often occuring together. We could test for bigrams (words that typically occur side by side) to see if this is the case. \n",
    "\n",
    "In order to perform this test, we must first convert our list of tokens into and NLTK text. We can then use specific NLTK functions on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'nltk.text.Text'>\n",
      "per annum; years old; twenty thousand; year old; hundred thousand; man\n",
      "talk; fine gentlemen; eight shillings; ten shillings; therefore\n",
      "humbly; solar year; already computed; fifty thousand; thousand\n",
      "carcasses; thousand couple; would become; three pounds; poor people;\n",
      "thousand children; two shillings\n"
     ]
    }
   ],
   "source": [
    "print(type(token_text))\n",
    "nltk_text = nltk.Text(token_text)\n",
    "print(type(nltk_text))\n",
    "nltk_text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "t two hundred thousand couple whose wives are breeders ; from which number I subtract thirty thousan\n",
      "e will remain an hundred and seventy thousand breeders . I again subtract fifty thousand , for those\n",
      " the publick , because they soon would become breeders themselves : And besides , it is not improbab\n",
      " we are yearly over-run , being the principal breeders of the nation , as well as our most dangerous\n",
      "wth and manufacture . Fourthly , The constant breeders , besides the gain of eight shillings sterlin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk_text.concordance('breeders', width=100)\n",
    "nltk_text.similar('breeders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 8 of 8 matches:\n",
      "land , from being a burden on their parents or country , and for making them be\n",
      " at a certain age , who are born of parents in effect as little able to support\n",
      "nstead of being a charge upon their parents , or the parish , or wanting food a\n",
      "nd twenty thousand children of poor parents annually born . The question theref\n",
      "n not turn to account either to the parents or kingdom , the charge of nutrimen\n",
      "y have already devoured most of the parents , seem to have the best title to th\n",
      "nd these to be disposed of by their parents if alive , or otherwise by their ne\n",
      "swer , that they will first ask the parents of these mortals , whether they wou\n",
      "children time want number arms backs heels nation age value charge\n",
      "parish rest cloathing souls county art fruits sale persons\n"
     ]
    }
   ],
   "source": [
    "nltk_text.concordance('parents')\n",
    "nltk_text.similar('parents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some linguistics..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Functional linguistics* is a research area concerned with how *realised language* (lexis and grammar) work to achieve meaningful social functions.\n",
    "\n",
    "One functional linguistic theory is *Systemic Functional Linguistics*, developed by Michael Halliday (Prof. Emeritus at University of Sydney).\n",
    "\n",
    "Central to the theory is a division between **experiential meanings** and **interpersonal meanings**.\n",
    "\n",
    "* Experiential meanings communicate what happened to whom, under what circumstances.\n",
    "* Interpersonal meanings negotiate identities and role relationships between speakers \n",
    "\n",
    "Halliday argues that these two kinds of meaning are realised **simultaneously** through different parts of English grammar.\n",
    "\n",
    "* Experiential meanings are made through **transitivity choices**.\n",
    "* Interpersonal meanings are made through **mood choices**\n",
    "\n",
    "\n",
    "Transitivity choices include fitting together configurations of:\n",
    "\n",
    "* Participants (*a man, green bikes*)\n",
    "* Processes (*sleep, has always been, is considering*)\n",
    "* Circumstances (*on the weekend*, *in Australia*)\n",
    "\n",
    "Mood features of a language include:\n",
    "\n",
    "* Mood types (*declarative, interrogative, imperative*)\n",
    "* Modality (*would, can, might*)\n",
    "* Lexical density--wordshe number of words per clause, the number of content to non-content words, etc.\n",
    "\n",
    "Lexical density is usually a good indicator of the general tone of texts. The language of academia, for example, often has a huge number of nouns to verbs. We can approximate an academic tone simply by making nominally dense clauses: \n",
    "\n",
    "      The consideration of interest is the potential for a participant of a certain demographic to be in Group A or Group B*.\n",
    "\n",
    "Notice how not only are there many nouns (*consideration*, *interest*, *potential*, etc.), but that the verbs are very simple (*is*, *to be*).\n",
    "\n",
    "In comparison, informal speech is characterised by smaller clauses, and thus more verbs.\n",
    "\n",
    "      A: Did you feel like dropping by?\n",
    "      B: I thought I did, but now I don't think I want to\n",
    "\n",
    "Here, we have only a few, simple nouns (*you*, *I*), with more expressive verbs (*feel*, *dropping by*, *think*, *want*)\n",
    "\n",
    "> **Note**: SFL argues that through *grammatical metaphor*, one linguistic feature can stand in for another. *Would you please shut the door?* is an interrogative, but it functions as a command. *invitation* is a nominalisation of a process, *invite*. We don't have time to deal with these kinds of realisations, unfortunately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of Fraser's speech, there are nearly twice as many nouns as verbs, and the verbs are generally quite simple ones (parts of To Be and To Have make up about a quarter). This suggests that Fraser's speech, even when giving a radio talk to his electorate, is more towards the formal end of the spectrum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "So far today we have:\n",
    "* Imported text into NLTK\n",
    "* Tokenised raw text into words\n",
    "* Tagged words as parts of speech\n",
    "* Converted a list into NLTK Text for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "Yesterday, when we did our frequency counts of the books in the NLTK Library, we noticed that a lot of speace was taken up by little words like 'and' and 'of' and 'the' which don't add a lot to our understanding of text. These are called 'stop words'. It will help our analysis if we exclude them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 363),\n",
       " ('the', 165),\n",
       " ('of', 128),\n",
       " ('and', 110),\n",
       " ('to', 107),\n",
       " ('a', 83),\n",
       " ('in', 70),\n",
       " ('.', 66),\n",
       " ('I', 55),\n",
       " ('be', 51),\n",
       " ('for', 41),\n",
       " ('that', 38),\n",
       " ('their', 37),\n",
       " ('will', 36),\n",
       " ('as', 35),\n",
       " ('or', 34),\n",
       " ('by', 34),\n",
       " ('have', 29),\n",
       " ('at', 28),\n",
       " ('they', 27)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_text = nltk.FreqDist(nltk_text)\n",
    "fdist_text.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3912\n",
      "1123\n"
     ]
    }
   ],
   "source": [
    "print(len(nltk_text))\n",
    "print(len(set(nltk_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3403\n",
      "1070\n"
     ]
    }
   ],
   "source": [
    "# find words, not punctuation\n",
    "text = [item for item in nltk_text if item.isalpha()]\n",
    "print(len(text))\n",
    "# capitalisation doesnt matter\n",
    "vocab = [word.lower() for word in text]\n",
    "print(len(set(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['modest', 'proposal', 'preventing', 'children', 'poor', 'people', 'ireland', 'burden', 'parents', 'country']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('children', 19),\n",
       " ('would', 18),\n",
       " ('kingdom', 15),\n",
       " ('one', 15),\n",
       " ('thousand', 15),\n",
       " ('country', 13),\n",
       " ('upon', 13),\n",
       " ('number', 11),\n",
       " ('may', 11),\n",
       " ('great', 10),\n",
       " ('therefore', 10),\n",
       " ('many', 9),\n",
       " ('child', 9),\n",
       " ('year', 9),\n",
       " ('parents', 8),\n",
       " ('well', 8),\n",
       " ('years', 8),\n",
       " ('two', 8),\n",
       " ('old', 8),\n",
       " ('hundred', 8)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopword list in nltk documentation\n",
    "from nltk.corpus import stopwords\n",
    "ignored_words = nltk.corpus.stopwords.words(\"english\")\n",
    "unstopped = [word for word in vocab if word not in ignored_words]\n",
    "print(unstopped[:10])\n",
    "fdist_unstop = nltk.FreqDist(unstopped)\n",
    "fdist_unstop.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list we have now is probably more intersting if we wanted to get a sense of the key issues in the text. Note, we're working with a very small sample here. This sort of analysis is much more useful over really big corpora.\n",
    "\n",
    "*Note: We could have condensed the first two steps into a single line of code that looked like this:*\n",
    "\n",
    "        unstopped = [word for word in speech if word.lower() not in stopwords.words('english') and word.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation\n",
    "We've just used collocation to test a hypothesis about the most common nouns in the speech we were investigating. Collocation can be quite a powerful tool for finding features of language.\n",
    "\n",
    "First, let's look for bigrams in the whole list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't tell us much. Let's try again with 'unstopped' our list of tokens with the punctuation and stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as identifying collocations (words that appear near each other), we can also look for n-grams or clusters, which appear immediately adjacent to each other. Repeated N-grams are a good way to get a sense of what a text is about. First, let's see how n-grams are created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of trigrams in the sentence, and they don't tell us much. It's when n-grams are repeated that they start to get interesting, but before we write code the code for that we need to have some knowledge of dictionaries..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a dictionaries\n",
    "\n",
    "We've already worked with strings and lists. Another kind of data structure in Python is a dictionary.\n",
    "Here is how a simple dictionary works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of dictionaries is to store a key (the word) and a value (the count). When you ask for the key, you get its value.\n",
    "\n",
    "Notice that you use curly braces for dictionaries, but square brackets for lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding duplicate ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last bit of code is more advanced. Don't worry if you forget what every line means. If you are interested getting more comfortable with Python, come to our [Python]('https://github.com/resbaz/2015-12-14-Python-for-Researchers') course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important skill for using NLTK in your life as a researchers is going to be working with your own texts. First, let's look at reading in text files directly from the web.\n",
    "\n",
    "Of course, a lot of the text you're going to want to work with won't be in handy text files already. That's where a Python library called Beautiful Soup comes in.\n",
    "\n",
    "*Note*: the ! is a way of accessing command line functions from the notebook. We could also do this in the terminal (without the !). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://en.wikipedia.org/wiki/Smog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "raw = urlopen(url).read()\n",
    "print(type(raw))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup breaks the single long string into its constituent parts, creating an object 'Beautiful Soup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(raw, 'html.parser')\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Smog is a type of air pollutant. The word \"smog\" was coined in the early 20th century as a portmanteau of the words smoke and fog to refer to smoky fog, its opacity, and odour.[1] The word was then intended to refer to what was sometimes known as pea soup fog, a familiar and serious problem in London from the 19th century to the mid 20th century. This kind of visible air pollution is composed of nitrogen oxides, sulfur oxides, ozone, smoke or particulates among others (less visible pollutants include carbon monoxide, CFCs and radioactive sources).[citation needed] Human-made smog is derived from coal emissions, vehicular emissions, industrial emissions, forest and agricultural fires and photochemical reactions of these emissions.', 'Modern smog, as found for example in Los Angeles, is a type of air pollution derived from vehicular emission from internal combustion engines and industrial fumes that react in the atmosphere with sunlight to form secondary pollutants that also combine with the primary emissions to form photochemical smog. In certain other cities, such as Delhi, smog severity is often aggravated by stubble burning in neighboring agricultural areas. The atmospheric pollution levels of Los Angeles, Beijing, Delhi, Mexico City, Tehran and other cities are increased by inversion that traps pollution close to the ground. It is usually highly toxic to humans and can cause severe sickness, shortened life or death.', '', '', 'Coinage of the term \"smog\" is generally attributed to Dr. Henry Antoine Des Voeux in his 1905 paper, \"Fog and Smoke\" for a meeting of the Public Health Congress. The July 26, 1905 edition of the London newspaper Daily Graphic quoted Des Voeux, \"He said it required no science to see that there was something produced in great cities which was not found in the country, and that was smoky fog, or what was known as \\'smog\\'.\"[2] The following day the newspaper stated that \"Dr. Des Voeux did a public service in coining a new word for the London fog.\" However, this is predated by a Los Angeles Times article of January 19, 1893, in which the word is attributed to \"a witty English writer.\"', \"Coal fires, used to heat individual buildings or in a power-producing plant, can emit significant clouds of smoke that contributes to smog. Air pollution from this source has been reported in England since the Middle Ages.[3][4] London, in particular, was notorious up through the mid-20th century for its coal-caused smogs, which were nicknamed 'pea-soupers.' Air pollution of this type is still a problem in areas that generate significant smoke from burning coal. The emissions from coal combustions are one of the main causes of air pollution in China.[5] Especially during autumn and winter when coal-fired heating ramps up, the amount of produced smoke forces some Chinese cities to close down roads, schools or airports. One prominent example for this was China's Northeastern city Harbin in 2013.\", 'Traffic emissions – such as from trucks, buses, and automobiles – also contribute.[6] Airborne by-products from vehicle exhaust systems cause air pollution and are a major ingredient in the creation of smog in some large cities.[7][8][9][10]', 'The major culprits from transportation sources are carbon monoxide (CO),[11][12] nitrogen oxides (NO and NOx),[13][14][15] volatile organic compounds,[12][13] sulfur dioxide,[12] and hydrocarbons.[12] (Hydrocarbons are the main components of petroleum fuels such as gasoline and diesel fuel.) These molecules react with sunlight, heat, ammonia, moisture, and other compounds to form the noxious vapors, ground level ozone, and particles that comprise smog.[12][13]', 'Photochemical smog is the chemical reaction of sunlight, nitrogen oxides and volatile organic compounds in the atmosphere, which leaves airborne particles and ground-level ozone.[16] This noxious mixture of air pollutants may include the following:', '\\nA primary pollutant is an air pollutant emitted directly from a source. A secondary pollutant is not directly emitted as such, but forms when other pollutants (primary pollutants) react in the atmosphere. Examples of a secondary pollutant include ozone, which is formed when hydrocarbons (HC) and nitrogen oxides (NOx) combine in the presence of sunlight; nitrogen dioxide (NO2), which is formed as nitric oxide (NO) combines with oxygen in the air; and acid rain, which is formed when sulfur dioxide or nitrogen oxides react with water.[17] All of these harsh chemicals are usually highly reactive and oxidizing. Photochemical smog is therefore considered to be a problem of modern industrialization. It is present in all modern cities, but it is more common in cities with sunny, warm, dry climates and a large number of motor vehicles.[18] Because it travels with the wind, it can affect sparsely populated areas as well.']\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for para in soup.find_all('p'):\n",
    "    text = para.text\n",
    "    texts.append(text)\n",
    "print(texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smog is a type of air pollutant. The word \"smog\" was coined in the early 20th century as a portmanteau of the words smoke and fog to refer to smoky fog, its opacity, and odour. The word was then intended to refer to what was sometimes known as pea soup fog, a familiar and serious problem in London from the 19th century to the mid 20th century. This kind of visible air pollution is composed of nitrogen oxides, sulfur oxides, ozone, smoke or particulates among others (less visible pollutants include carbon monoxide, CFCs and radioactive sources).[citation needed] Human-made smog is derived from coal emissions, vehicular emissions, industrial emissions, forest and agricultural fires and photochemical reactions of these emissions.\n",
      "Modern smog, as found for example in Los Angeles, is a type of air pollution derived from vehicular emission from internal combustion engines and industrial fumes that react in the atmosphere with sunlight to form secondary pollutants that also combine with the p\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regex = re.compile('\\[[0-9]*\\]')\n",
    "joined_texts = '\\n'.join(texts)\n",
    "joined_texts = re.sub(regex, '', joined_texts)\n",
    "print(joined_texts[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work on the text, the first step is to tokenise it into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smog', 'is', 'a', 'type', 'of', 'air', 'pollutant', '.']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = nltk.word_tokenize(joined_texts)\n",
    "wordlist[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some other types of analysis, we'll need to create an NLTK text object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n"
     ]
    }
   ],
   "source": [
    "smog_text = nltk.Text(wordlist)\n",
    "print(type(smog_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once we've done all that work creating clean text, it's a good idea to save it for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 47 matches:\n",
      "                                     Smog is a type of air pollutant . The wor\n",
      "                                     smog '' was coined in the early 20th cent\n",
      "s ) . [ citation needed ] Human-made smog is derived from coal emissions , veh\n",
      "eactions of these emissions . Modern smog , as found for example in Los Angele\n",
      "mary emissions to form photochemical smog . In certain other cities , such as \n",
      "rtain other cities , such as Delhi , smog severity is often aggravated by stub\n",
      "fe or death . Coinage of the term `` smog '' is generally attributed to Dr. He\n",
      " clouds of smoke that contributes to smog . Air pollution from this source has\n",
      " major ingredient in the creation of smog in some large cities . The major cul\n",
      " ozone , and particles that comprise smog . Photochemical smog is the chemical\n",
      "s that comprise smog . Photochemical smog is the chemical reaction of sunlight\n",
      "active and oxidizing . Photochemical smog is therefore considered to be a prob\n",
      " reactions involved in photochemical smog were not understood until the 1950s \n",
      " ozone as a component of Los Angeles smog . Haagen-Smit went on to discover th\n",
      "formation of ozone and photochemical smog . :219–224 Haagen-Smit worked with A\n",
      "oped various equipment for detecting smog , ranging from an `` Apparatus for r\n",
      "wo key components to the creation of smog . However , the smog created as a re\n",
      "the creation of smog . However , the smog created as a result of a volcanic er\n",
      "s been linked to the distribution of smog in some areas . For example , the cr\n",
      " has been shown to have an effect on smog distribution that is more than fossi\n",
      " than fossil fuel combustion alone . Smog is a serious problem in many cities \n",
      "on similar to that of the 1952 Great Smog of London . The results from this ex\n",
      "sing the ongoing effect of the Great Smog . The U.S. EPA has developed an Air \n",
      "o Medical Association announced that smog is responsible for an estimated 9,50\n",
      " who had healthy babies , found that smog in the San Joaquin Valley area of Ca\n"
     ]
    }
   ],
   "source": [
    "smog_text.concordance('smog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cynthiiee\n",
      "/Users/cynthiiee/smog\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "! mkdir smog\n",
    "%cd smog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37487"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLTK_file = open(\"NLTK-smog.txt\", \"w\", encoding=\"UTF-8\")\n",
    "NLTK_file.write(str(wordlist))\n",
    "NLTK_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"Smog-text.txt\", \"w\", encoding=\"UTF-8\")\n",
    "text_file.write(joined_texts)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a look at the two files you've created in the file management system. Open them. How is the nltk file different from the .txt file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge!**\n",
    "* Find a webpage of interest to your studies and use Beautiful Soup to extract the text\n",
    "* Tokenise the text\n",
    "* Find the most common words in your text (Extension: remove the stop words)\n",
    "* Find trigrams in your text \n",
    "* Save your text to a text file\n",
    "\n",
    "*Hint*: feel free to collude with your neighbours and please copy and paste our previous code! Copying and pasting are essential skills of developers, as well as googling error messages (seriously!). If you don't believe me, ask a computer scientist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Handstand\"\n",
    "raw = urlopen(url).read()\n",
    "print(type(raw))\n",
    "soup = BeautifulSoup(raw, 'html.parser')\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A handstand is the act of supporting the body in a stable, inverted vertical position by balancing on the hands. In a basic handstand the body is held straight with arms and legs fully extended, with hands spaced approximately shoulder-width apart. There are many variations of handstands, but in all cases a handstand performer must possess adequate balance and upper body strength.', 'Handstands are performed in many athletic activities, including acro dance, cheerleading, circus, yoga, and gymnastics. Some variation of handstand is performed on every gymnastic apparatus, and many tumbling skills pass through a handstand position during their execution. Breakdancers incorporate handstands in freezes and kicks. Armstand dives—a category found in competitive platform diving—are dives that begin with a handstand. In games or contests, swimmers perform underwater handstands with their legs and feet extended above the water.', 'Handstands are known by various other names. In yoga, the handstand is known as Adho Mukha Vrksasana[1] translating to Downward-facing Tree Pose. In capoeira it is named bananeira.', 'There are two basic handstand styles in modern gymnastics: curved-back and straight-back.[2] Straight-back style is employed when the aesthetics of straight body lines are desired and feasible. In many cases (e.g., when a handstand is being performed in conjunction with a gymastic apparatus), however, the curved-back style is preferred as it offers superior control over balance. In all cases, balance is maintained by shifting body weight towards the fingers or the heel of the hand.', 'All basic gymnastic handstands have these characteristics:', 'In addition, straight-back handstands have these characteristics:', 'Handstand \"freezes\" are common in breakdance, in which dancers strive to assume visually interesting body shapes that are not subject to formal rules.', 'Common handstand variations include:', 'Blood pressure in the head increases to abnormally high levels when the body is inverted. When one is inverted for extended periods, the prolonged high blood pressure may exacerbate preexisting medical conditions and increase the risk of stroke, pulmonary oedema, and other ailments.[3]']\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for para in soup.find_all('p'):\n",
    "    text = para.text\n",
    "    texts.append(text)\n",
    "print(texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A handstand is the act of supporting the body in a stable, inverted vertical position by balancing on the hands. In a basic handstand the body is held straight with arms and legs fully extended, with hands spaced approximately shoulder-width apart. There are many variations of handstands, but in all cases a handstand performer must possess adequate balance and upper body strength.\n",
      "Handstands are performed in many athletic activities, including acro dance, cheerleading, circus, yoga, and gymnastics. Some variation of handstand is performed on every gymnastic apparatus, and many tumbling skills pass through a handstand position during their execution. Breakdancers incorporate handstands in freezes and kicks. Armstand dives—a category found in competitive platform diving—are dives that begin with a handstand. In games or contests, swimmers perform underwater handstands with their legs and feet extended above the water.\n",
      "Handstands are known by various other names. In yoga, the handstand is\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile('\\[[0-9]*\\]')\n",
    "joined_texts2 = '\\n'.join(texts)\n",
    "joined_texts2 = re.sub(regex, '', joined_texts2)\n",
    "print(joined_texts2[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'handstand', 'is', 'the', 'act', 'of', 'supporting', 'the']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = nltk.word_tokenize(joined_texts2)\n",
    "wordlist[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 20),\n",
       " ('.', 18),\n",
       " ('the', 15),\n",
       " ('is', 11),\n",
       " ('handstand', 10),\n",
       " ('in', 10),\n",
       " ('and', 10),\n",
       " ('body', 7),\n",
       " ('a', 7),\n",
       " ('In', 7)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(wordlist)\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('in', 17),\n",
       " ('the', 15),\n",
       " ('handstand', 11),\n",
       " ('is', 11),\n",
       " ('and', 10),\n",
       " ('a', 8),\n",
       " ('body', 7),\n",
       " ('are', 7),\n",
       " ('handstands', 7),\n",
       " ('of', 6)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find words, not punctuation\n",
    "text = [item for item in wordlist if item.isalpha()]\n",
    "print(len(text))\n",
    "# capitalisation doesnt matter\n",
    "vocab = [word.lower() for word in text]\n",
    "print(len(set(vocab)))\n",
    "fdist_vocab = nltk.FreqDist(vocab)\n",
    "fdist_vocab.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['handstand', 'act', 'supporting', 'body', 'stable', 'inverted', 'vertical', 'position', 'balancing', 'hands']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('handstand', 11),\n",
       " ('body', 7),\n",
       " ('handstands', 7),\n",
       " ('many', 4),\n",
       " ('inverted', 3),\n",
       " ('basic', 3),\n",
       " ('extended', 3),\n",
       " ('cases', 3),\n",
       " ('balance', 3),\n",
       " ('performed', 3)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unstopped = [word for word in vocab if word not in ignored_words]\n",
    "print(unstopped[:10])\n",
    "fdist_unstop = nltk.FreqDist(unstopped)\n",
    "fdist_unstop.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "                                   handstand is the act of supporting the body \n",
      "alancing on the hands . In a basic handstand the body is held straight with arm\n",
      "of handstands , but in all cases a handstand performer must possess adequate ba\n",
      "and gymnastics . Some variation of handstand is performed on every gymnastic ap\n",
      "any tumbling skills pass through a handstand position during their execution . \n",
      "diving—are dives that begin with a handstand . In games or contests , swimmers \n",
      "arious other names . In yoga , the handstand is known as Adho Mukha Vrksasana t\n",
      "ed bananeira . There are two basic handstand styles in modern gymnastics : curv\n",
      "le . In many cases ( e.g. , when a handstand is being performed in conjunction \n",
      "tands have these characteristics : Handstand `` freezes '' are common in breakd\n",
      "t subject to formal rules . Common handstand variations include : Blood pressur\n"
     ]
    }
   ],
   "source": [
    "hand_text = nltk.Text(wordlist)\n",
    "hand_text.concordance('handstand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
